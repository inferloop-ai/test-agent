apiVersion: v1
kind: Agent
metadata:
  name: langgraph-table-agent
  description: LangGraph agent for analyzing and visualizing table data using local Llama model via Ollama
spec:
  runtime:
    image: langgraph-table-agent:0.1.0
    entrypoint: ["python", "main.py"]
    env:
      - name: OLLAMA_BASE_URL
        default: http://host.docker.internal:11434
        description: Ollama API endpoint URL
      - name: LLM_MODEL
        default: llama3.2
        description: Name of the Llama model to use
      - name: OUTPUT_DIR
        default: /app/outputs
        description: Directory for output files
    ports:
      - 8080
  commands:
    test: ["python", "main.py", "test"]
    chat: ["python", "main.py", "chat"]
    run: ["python", "main.py", "run"]